"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ LangChain –æ–±–µ—Ä—Ç–∫–∏ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
–ü—Ä–∏–Ω–∏–º–∞—é—Ç –æ–¥–∏–Ω —Å—Ç—Ä–æ–∫–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
"""

from langchain.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Type
import os
import sys
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –Ω–∞—à–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

from src.tools.file_tools import (
    ListDirTool,
    ReadFileTool,
    EditFileTool,
    GrepTool,
    TerminalTool
)
from src.tools.semantic_search import SemanticSearchTool


class SimpleListDirInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    path: str = Field(description="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π)")


class SimpleListDirLangChain(BaseTool):
    """–ü—Ä–æ—Å—Ç–∞—è LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    name: str = "list_directory"
    description: str = """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–´–ï –ü–£–¢–ò –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞.
    –ü—Ä–∏–º–µ—Ä—ã: ".", "src", "docs"
    """
    args_schema: Type[BaseModel] = SimpleListDirInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = ListDirTool(workspace_path)
    
    def _run(self, path: str) -> str:
        # –û—á–∏—â–∞–µ–º –ø—É—Ç—å –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_path = path.strip()
        result = self._tool.execute(clean_path)
        
        if not result["success"]:
            return f"‚ùå –û—à–∏–±–∫–∞: {result['error']}"
        
        output = [f"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {result['path']}"]
        output.append(f"üìä –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {result['total']}")
        output.append("")
        
        for entry in result["entries"]:
            icon = "üìÅ" if entry["is_directory"] else "üìÑ"
            size = f" ({entry['size']} –±–∞–π—Ç)" if not entry["is_directory"] else ""
            output.append(f"{icon} {entry['name']}{size}")
        
        return "\n".join(output)


class SimpleReadFileInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤"""
    file_path: str = Field(description="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —á—Ç–µ–Ω–∏—è (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π)")


class SimpleReadFileLangChain(BaseTool):
    """–ü—Ä–æ—Å—Ç–∞—è LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤"""
    name: str = "read_file"
    description: str = """–ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–´–ï –ü–£–¢–ò –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞.
    –ü—Ä–∏–º–µ—Ä—ã: "README.md", "src/main.py", "docs/guide.md"
    """
    args_schema: Type[BaseModel] = SimpleReadFileInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = ReadFileTool(workspace_path)
    
    def _run(self, file_path: str) -> str:
        # –û—á–∏—â–∞–µ–º –ø—É—Ç—å –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_path = file_path.strip()
        result = self._tool.execute(clean_path)
        
        if not result["success"]:
            return f"‚ùå –û—à–∏–±–∫–∞: {result['error']}"
        
        output = [f"üìÑ –§–∞–π–ª: {result['path']}"]
        output.append("")
        output.append(result["content"])
        
        return "\n".join(output)


class SimpleEditFileInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤"""
    input_data: str = Field(description="JSON —Å—Ç—Ä–æ–∫–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {\"file_path\": \"path\", \"old_string\": \"old\", \"new_string\": \"new\"}")


class SimpleEditFileLangChain(BaseTool):
    """–ü—Ä–æ—Å—Ç–∞—è LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤"""
    name: str = "edit_file"
    description: str = """–†–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –∑–∞–º–µ–Ω–æ–π —Å—Ç—Ä–æ–∫.
    
    –ü–µ—Ä–µ–¥–∞–π JSON —Å—Ç—Ä–æ–∫—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
    {"file_path": "path/to/file", "old_string": "—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–º–µ–Ω—ã", "new_string": "–Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç"}
    
    –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π old_string="" –∏ new_string="—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞"
    """
    args_schema: Type[BaseModel] = SimpleEditFileInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = EditFileTool(workspace_path)
    
    def _run(self, input_data: str) -> str:
        try:
            # –û—á–∏—â–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_input = input_data.strip()
            data = json.loads(clean_input)
            file_path = data["file_path"].strip()
            old_string = data.get("old_string", "")
            new_string = data["new_string"]
            
            result = self._tool.execute(file_path, old_string, new_string)
            
            if not result["success"]:
                return f"‚ùå –û—à–∏–±–∫–∞: {result['error']}"
            
            return f"‚úÖ –§–∞–π–ª {result['path']} –∏–∑–º–µ–Ω–µ–Ω. –ó–∞–º–µ–Ω–µ–Ω–æ {result['replacements_made']} –≤—Ö–æ–∂–¥–µ–Ω–∏–π."
            
        except json.JSONDecodeError:
            return "‚ùå –û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π JSON —Ñ–æ—Ä–º–∞—Ç"
        except KeyError as e:
            return f"‚ùå –û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä {e}"


class SimpleGrepInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞"""
    pattern: str = Field(description="–ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞")


class SimpleGrepLangChain(BaseTool):
    """–ü—Ä–æ—Å—Ç–∞—è LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞"""
    name: str = "grep_search"
    description: str = """–ò—â–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞.
    
    –ü–µ—Ä–µ–¥–∞–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞. –ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞.
    –ü—Ä–∏–º–µ—Ä—ã: "import", "function", "class MyClass"
    """
    args_schema: Type[BaseModel] = SimpleGrepInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = GrepTool(workspace_path)
    
    def _run(self, pattern: str) -> str:
        # –û—á–∏—â–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_pattern = pattern.strip()
        result = self._tool.execute(clean_pattern)
        
        if not result["success"]:
            return f"‚ùå –û—à–∏–±–∫–∞: {result['error']}"
        
        if not result["matches"]:
            return f"üîç –ü–æ–∏—Å–∫ '{clean_pattern}': —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        
        output = [f"üîç –ü–æ–∏—Å–∫ '{clean_pattern}': –Ω–∞–π–¥–µ–Ω–æ {len(result['matches'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"]
        output.append("")
        
        for match in result["matches"]:
            output.append(f"üìÑ {match['file']}:{match['line']} - {match['content'].strip()}")
        
        return "\n".join(output)


class SimpleTerminalInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"""
    command: str = Field(description="–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")


class SimpleTerminalLangChain(BaseTool):
    """–ü—Ä–æ—Å—Ç–∞—è LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"""
    name: str = "run_terminal"
    description: str = """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—ã –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ.
    
    –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥: "python --version", "ls", "dir", "echo Hello"
    """
    args_schema: Type[BaseModel] = SimpleTerminalInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = TerminalTool(workspace_path)
    
    def _run(self, command: str) -> str:
        # –û—á–∏—â–∞–µ–º –∫–æ–º–∞–Ω–¥—É –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_command = command.strip()
        result = self._tool.execute(clean_command)
        
        if not result["success"]:
            return f"‚ùå –û—à–∏–±–∫–∞: {result['error']}"
        
        output = [f"üíª –ö–æ–º–∞–Ω–¥–∞: {clean_command}"]
        output.append("")
        output.append(f"üìä –ö–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞: {result['return_code']}")
        output.append("")
        
        if result["stdout"]:
            output.append("üì§ –í—ã–≤–æ–¥:")
            output.append(result["stdout"])
        
        if result["stderr"]:
            output.append("‚ö†Ô∏è –û—à–∏–±–∫–∏:")
            output.append(result["stderr"])
        
        return "\n".join(output)


class SimpleSemanticSearchInput(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    query: str = Field(description="–ó–∞–ø—Ä–æ—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Å–º—ã—Å–ª—É")


class SimpleSemanticSearchLangChain(BaseTool):
    """LangChain –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    name: str = "semantic_search"
    description: str = """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥–æ–≤–æ–π –±–∞–∑–µ –ø–æ —Å–º—ã—Å–ª—É.
    
    –ò—â–µ—Ç –∫–æ–¥ –Ω–µ –ø–æ —Ç–æ—á–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É, –∞ –ø–æ —Å–º—ã—Å–ª—É –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
    –ü—Ä–∏–º–µ—Ä—ã: "–∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", "—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"
    
    –≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –Ω–∞—Ö–æ–¥–∏—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–π –∫–æ–¥ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π –æ—Ç–ª–∏—á–∞—é—Ç—Å—è.
    """
    args_schema: Type[BaseModel] = SimpleSemanticSearchInput
    
    def __init__(self, workspace_path: str):
        super().__init__()
        self._tool = SemanticSearchTool(workspace_path)
    
    def _run(self, query: str) -> str:
        clean_query = query.strip()
        result = self._tool.execute(clean_query)
        
        if not result["success"]:
            return f"‚ùå –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {result['error']}"
        
        if "results" not in result or not result["results"]:
            return f"üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ '{clean_query}': —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        
        output = [f"üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ '{clean_query}': –Ω–∞–π–¥–µ–Ω–æ {len(result['results'])} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"]
        output.append("")
        
        for item in result["results"]:
            score_percent = int(item["score"] * 100)
            output.append(f"üìÑ {item['file']}:{item['lines']} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score_percent}%)")
            # Show preview of content
            preview = item["content"].replace('\n', ' ').strip()
            if len(preview) > 150:
                preview = preview[:150] + "..."
            output.append(f"   üí° {preview}")
            output.append("")
        
        return "\n".join(output)


def create_simple_langchain_tools() -> List[BaseTool]:
    """–°–æ–∑–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Å—Ç—ã—Ö LangChain –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
    from ..workspace import get_workspace
    workspace = get_workspace()
    workspace_path = str(workspace.current_path) if workspace.current_path else "."
    
    return [
        SimpleListDirLangChain(workspace_path),
        SimpleReadFileLangChain(workspace_path),
        SimpleEditFileLangChain(workspace_path),
        SimpleGrepLangChain(workspace_path),
        SimpleTerminalLangChain(workspace_path),
        SimpleSemanticSearchLangChain(workspace_path)
    ]


def get_simple_tool_descriptions() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
    descriptions = [
        "list_directory: –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏",
        "read_file: –ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞",
        "edit_file: –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –∑–∞–º–µ–Ω–æ–π —Å—Ç—Ä–æ–∫",
        "grep_search: –ò—â–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞",
        "run_terminal: –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—ã –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ",
        "semantic_search: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥–æ–≤–æ–π –±–∞–∑–µ –ø–æ —Å–º—ã—Å–ª—É –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"
    ]
    return "\n".join(descriptions) 